<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Talks Slideshow</title>
    <link rel="stylesheet" href="styles.css">
</head>

<!--
    INTRODUCTION SECTION:
    The introduction section serves to establish your credibility as a presenter and to provide context for the audience. 
    By sharing your background and motivation, you help the audience understand why they should listen to you and how the presentation will benefit them.
    The agenda slide gives a clear overview of what will be covered, setting expectations and providing a roadmap for the presentation.
    This section aligns with the goal of engaging the audience and preparing them to learn about generative AI.
-->

<!--
    AI BASICS SECTION:
    The AI basics section is crucial for building a foundation of understanding for non-experts. 
    By explaining key concepts such as artificial intelligence, machine learning, and supervised learning,
    you provide the audience with the necessary background knowledge to grasp the more advanced topics later in the presentation.
    The minimal example of classifying cats and dogs helps to make the concepts more concrete and relatable.
    This section aligns with the goal of providing a solid mental model by starting with the fundamentals and gradually building up to more complex ideas.
-->

<!--
    LARGE LANGUAGE MODELS SECTION:
    The large language models section dives into the specifics of LLMs, which are a key component of recent developments in generative AI.
    By explaining what LLMs are, how they work, and providing examples like ChatGPT, you help the audience understand the underlying technology behind popular AI tools.
    The discussion of the attention mechanism and the importance of training data helps to demystify the "magic" of AI and provides insights into how these models generate human-like text.
    The tips for effective LLM use and the emphasis on responsible AI development align with the goal of enabling the audience to improve their use of these tools and evaluate hype claims.
-->

<!--
    DIFFUSION MODELS SECTION:
    The diffusion models section introduces another important aspect of generative AI: media generation.
    By providing a high-level overview of the diffusion process and showcasing impressive generated images, you capture the audience's attention and demonstrate the potential of this technology.
    The discussion of current limitations and the demo of Comfy UI helps to ground the audience's expectations and provides practical insights into how these tools can be used.
    The tips for prompt engineering and the discussion of recent advances align with the goal of enabling the audience to effectively use these tools and stay informed about the latest developments.
-->

<!--
    CONCLUSION SECTION:
    The conclusion section serves to reinforce the key points covered in the presentation and to leave the audience with a lasting impression.
    By summarizing the main ideas and discussing the potential implications for AGI, you encourage the audience to continue exploring and thinking critically about these technologies.
    The call for responsible development and the opportunity for questions and discussion align with the goal of empowering the audience to engage with generative AI in a thoughtful and informed manner.
-->

<body>

    <!-- 
        SECTION START: INTRODUCTION
    -->

    <div class="slide">
        <div>
            <h2>Who Am I?</h2>
            <ul>
                <li>Software developer with a BSc in Computer Science.</li>
                <li>About a year experience in utilizing LLMs (ChatGPT) every day at work.</li>
                <ul>
                    <li>I don't develop AI systems, rather I utilize them to improve my programming.</li>
                </ul>
                <li>I have voraciously consuming the latest developments in generative AI.</li>
                <li>Personal anecdote: Using Dalle-3 and GPT-4 to create custom stickers for my laptop.</li>
                <ul>
                    <li>Generated bird characters with hats using Dalle-3</li>
                    <li>Used GPT-4 to write code for removing backgrounds and printing sticker sheets</li>
                </ul>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Why learn about AI tools?</h2>
            <ul>
                <li><strong>Empowerment:</strong> Leveraging AI tools can empower you to create amazing work.</li>
                <ul>
                    <li>Like any skill utilizing AI tools improves with practice.</li>
                </ul>
                <li><strong>Rapid Improvement:</strong> AI is improving at a breathtaking pace, it seems likely that
                    almost all 'knowledge' and artist professions will be changed forever.</li>
                <ul>
                    <li>New jobs and artist developments will challenge existing institutions.</li>
                </ul>
                <li><strong>Informed Evaluation:</strong> Understanding how these tools work enables evaluation of 'AI
                    hype'.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Rapid Improvement?</h2>
            <img src="gpt_graph.png" alt="GPT Model Growth Graph" style="max-width:100%;height:auto;">
        </div>
    </div>
    
    <div class="slide">
        <div>
            <h2>Presentation structure</h2>
            <ul>
                <li>AI basics üß†</li>
                <ul>
                    <li>Key terms: AI, AGI</li>
                    <li>High-level walkthrough of image classification as a minimal example of a neural network</li>
                </ul>
                <li>Deep dive into Large Language Models üó£Ô∏è</li>
                <ul>
                    <li>Focus on next word prediction and attention mechanism</li>
                    <li>Concrete demonstrations to build an effective mental model</li>
                </ul>
                <li>Diffusion models for media generation üé®</li>
                <ul>
                    <li>A whirlwind tour of media generation and future prospects</li>
                </ul>
                <li>Conclusion and AI trajectory üöÄ</li>
                <ul>
                    <li>Scaling laws and model parameter count</li>
                    <li>Speculation about the capacity of models powered by next-generation computers</li>
                    <li>Tying back to the discussion of AGI and its implications</li>
                </ul>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: AI BASICS
    -->
    <div class="slide">
        <div>
            <h2>Defining Artificial Intelligence (AI)</h2>
            <ul>
                <li>AI encompasses the development of computer systems capable of performing tasks that traditionally
                    require human intelligence.</li>
                <li>
                    <strong>Task-Specific AI:</strong>
                    <ul>
                        <li>Designed for specialized tasks, demonstrating intelligence in a narrow domain.</li>
                        <li>image recognition is an example of this kind of AI.</li>
                    </ul>
                </li>
                <li>
                    <strong>General AI (AGI):</strong>
                    <ul>
                        <li>Systems that excel across a wide range of tasks outperforming human capabilities.</li>
                        <li>Such a system could potentially improve itself.</li>
                    </ul>
                </li>
                <li>
                    <strong>Shifting Perception of AI</strong>
                    <ul>
                        <li>AI definition is fluid, adapting over time.</li>
                        <li>Computers achieve tasks once thought uniquely human.</li>
                        <li>Past AI breakthroughs may not be considered AI anymore.</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>


    <div class="slide">
        <!-- Speaker's Notes:
        - Adaptability: Machine learning models become more accurate as they process more data, contrasting with the static nature of traditional programs.
        - Generalization: These models can generalize from their training data to recognize and act upon patterns in new data, a task that is complex for traditional programming.
        - Efficiency: Automating the learning process from data itself makes machine learning viable for solving really complex problems. 
        -->
        <div>
            <h2>Machine Learning: Bridging Data and AI</h2>
            <ul>
                <li>Unlike traditional programming, which relies on explicit rules, machine learning empowers computers
                    to
                    learn from data, improving their ability to perform tasks over time.</li>
                <li><strong>Adaptability:</strong> Models refine their accuracy with each new piece of data.</li>
                <li><strong>Generalization:</strong> They apply learned patterns to new, unseen situations.</li>
                <li><strong>Efficiency:</strong> This approach streamlines the development of complex AI systems.</li>
            </ul>
        </div>
    </div>




    <div class="slide">
        <!-- 
            There are three main types of Machine Learning: supervised learning, unsupervised learning, and reinforcement learning.
            Supervised learning involves learning from labeled data, where the desired output is known.
            The algorithm learns to map input data to the correct output labels.
            Unsupervised learning involves finding patterns and structures in unlabeled data.
            The algorithm discovers hidden patterns or groupings in the data without any predefined labels. 
            Reinforcement learning involves an agent learning to make decisions through interaction with an environment. 
            The agent learns by receiving rewards or penalties for its actions.
        -->
        <div>
            <h2>Three Types of Machine Learning</h2>
            <ul>
                <li>Three Types of Machine Learning</li>
                <li>Supervised Learning</li>
                <ul>
                    <li>Learning from labeled data</li>
                    <li>Mapping input data to correct output labels</li>
                </ul>
                <li>Unsupervised Learning</li>
                <ul>
                    <li>Finding patterns in unlabeled data</li>
                    <li>Discovering hidden patterns or groupings</li>
                </ul>
                <li>Reinforcement Learning</li>
                <ul>
                    <li>Learning through interaction with an environment</li>
                    <li>Receiving rewards or penalties for actions</li>
                </ul>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Supervised learning is the most common type of Machine Learning and is widely used in applications like image classification. 
            In supervised learning, the algorithm is trained on a labeled dataset,
            where each example consists of an input (e.g., an image) and its corresponding output label (e.g., "cat" or "dog").
            The goal is to learn a mapping function that can predict the correct label for new, unseen input data. 
            Image classification is a popular application of supervised learning, where the task is to assign a class label to an input image based on its content.
        -->
        <div>
            <h2>Supervised Learning and Image Classification</h2>
            <ul>
                <li>Supervised Learning</li>
                <li>Most common type of Machine Learning</li>
                <li>Trained on labeled data (input + corresponding output label)</li>
                <li>Learns a mapping function to predict labels for new data</li>
                <li>Image Classification</li>
                <li>Application of supervised learning</li>
                <li>Assigning class labels to input images based on content</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Let's consider a minimal example of image classification: distinguishing between images of cats and dogs.
            To train a machine learning model for this task, we need a labeled dataset consisting of images of cats and dogs, along with their respective labels.
            The dataset is typically split into a training set, used to train the model, and a test set, used to evaluate the model's performance on unseen data. 
            The model learns to extract relevant features from the images and map them to the corresponding labels during training.
        -->
        <div>
            <h2>A Minimal Example: Classifying Cats and Dogs</h2>
            <ul>
                <li>Example: Classifying Cats and Dogs</li>
                <li>Labeled dataset:</li>
                <ul>
                    <li>Images of cats and dogs</li>
                    <li>Corresponding labels ("cat" or "dog")</li>
                </ul>
                <li>Dataset split:</li>
                <ul>
                    <li>Training set: Used to train the model</li>
                    <li>Test set: Used to evaluate the model's performance</li>
                </ul>
                <li>Model learns to extract features and map them to labels</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Labeled data plays a crucial role in supervised learning, as it provides the ground truth for the model to learn from.
            Each example in the labeled dataset consists of an input (e.g., an image) and its corresponding output label (e.g., "cat" or "dog").
            The quality and diversity of the labeled data directly impact the model's performance and its ability to generalize to new, unseen data.
            Collecting and annotating large amounts of labeled data can be time-consuming and expensive, but it is essential for training accurate models.
        -->
        <div>
            <h2>The Role of Labeled Data</h2>
            <ul>
                <li>Labeled Data: Crucial for Supervised Learning</li>
                <li>Each example: Input + Corresponding Output Label</li>
                <li>Quality and diversity of labeled data impact model performance</li>
                <li>Collecting and annotating labeled data can be time-consuming and expensive</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Training an image classifier involves feeding the labeled dataset to a machine learning model, typically a neural network.
            The model learns to map input images to their corresponding labels by adjusting its internal parameters. 
            During training, the model's performance is measured using a loss function, which quantifies the difference between the predicted labels and the true labels.
            The model's parameters are iteratively updated to minimize the loss function, allowing the model to improve its predictions over time.
            The training process continues until the model reaches a satisfactory level of performance on the training data.
        -->
        <div>
            <h2>Training the Image Classifier</h2>
            <ul>
                <li>Training an Image Classifier</li>
                <li>Feed labeled dataset to a machine learning model (neural network)</li>
                <li>Model learns to map input images to corresponding labels</li>
                <li>Loss function measures the model's performance</li>
                <li>Model's parameters are updated to minimize the loss</li>
                <li>Training continues until satisfactory performance is reached</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            After training, it is crucial to evaluate the model's performance on unseen data to assess its ability to generalize.
            The test set, which consists of labeled examples that were not used during training, is used for evaluation.
            Common evaluation metrics for image classification include accuracy, precision, recall, and F1 score. 
            Accuracy measures the overall correctness of the model's predictions, while precision and recall focus on the model's performance for each class. 
            If the model performs well on the test set, it indicates that it has learned meaningful patterns and can generalize to new data. 
            However, if the model performs poorly on the test set, it may suggest issues like overfitting or biased data. 
        -->
        <div>
            <h2>Evaluating the Trained Model</h2>
            <ul>
                <li>Evaluating the Trained Model</li>
                <li>Assess the model's performance on unseen data (test set)</li>
                <li>Evaluation metrics:</li>
                <ul>
                    <li>Accuracy: Overall correctness of predictions</li>
                    <li>Precision and Recall: Performance for each class</li>
                </ul>
                <li>Good performance on the test set indicates generalization ability</li>
                <li>Poor performance may suggest overfitting or biased data</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            The principles of supervised learning, as demonstrated in the image classification example, extend to other domains and applications of AI. 
            Generative AI is an exciting area that focuses on creating new content, such as images, text, or music, based on learned patterns from training data.
            Generative models, like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs),
            learn to capture the underlying distribution of the training data and generate new samples that resemble the original data.
            The success of generative AI relies on large-scale datasets, advanced model architectures, and powerful computational resources.
            Generative AI has the potential to revolutionize various industries, from creative applications like art and design to practical use cases like data augmentation and simulation.
        -->
        <div>
            <h2>From Image Classification to Generative AI</h2>
            <ul>
                <li>From Image Classification to Generative AI</li>
                <li>Principles of supervised learning extend to other domains</li>
                <li>Generative AI: Creating new content based on learned patterns</li>
                <li>Generative models (GANs, VAEs) capture data distribution and generate new samples</li>
                <li>Success relies on large-scale datasets, advanced architectures, and computational resources</li>
                <li>Potential to revolutionize industries (art, design, data augmentation, simulation)</li>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: LARGE LANGUAGE MODELS
    -->

    <div class="slide">
        <!-- 
            Explain what an LLM is and how it works.
            Discuss ChatGPT as a popular example of an LLM.
            Mention that LLMs are based on the attention mechanism and are essentially next-word prediction engines.
        -->
        <div>
            <h2>Large Language Models</h2>
            <ul>
                <li>What is an LLM?</li>
                <li>ChatGPT is a commercial product running on the GPT-3.5 or GPT-4 model</li>
                <li>Related to what people have seen (i.e., GPT-3.5)</li>
                <li>The most popular example is a large language model (LLM) based on the attention mechanism</li>
                <li>LLMs are next-word prediction engines</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Explain how an LLM generates text using a parameters file.
            Discuss the size of the parameters file and the hardware requirements for the best models.
            Mention that the parameters file is the result of training the neural network on a large corpus of text data.
            Highlight that the best models train on a substantial portion of the internet data at a huge expense.
        -->
        <div>
            <h2>What is inside an LLM?</h2>
            <ul>
                <li>An LLM generates text by referencing a parameters file to predict the next word in the sequence
                </li>
                <li>This file can be small and run on consumer hardware (think Macbook)</li>
                <li>The best models use huge parameters files (hundreds of GBs) and require specialized hardware
                </li>
                <li>A parameters file is the result of training the neural network</li>
                <li>This process compresses info from the training data into the output file</li>
                <li>The training data is often a corpus of text scraped off the internet (think sites like Reddit or
                    Wikipedia)</li>
                <li>The best models train on a substantial portion of the data available on the internet at huge
                    expense</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!--
            Explain the attention mechanism as the key innovation in LLMs.
            Compare the performance of traditional text prediction (e.g., phone keyboards) with LLMs like GPT-3.5.
            Provide examples to illustrate the difference in text completion quality between traditional methods and LLMs.
        -->
        <div>
            <h2>The Attention Mechanism</h2>
            <ul>
                <li>Attention as the key innovation in LLMs</li>
                <li>Text prediction has existed for a long time, but hasn't been particularly impressive</li>
                <li>Example: "I went to the Calgary Stampede and met a nice [day]" (phone keyboard)</li>
                <li>Example: "I went to the Calgary Stampede and met a nice [cowboy]." (GPT-3.5)</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!--
            Provide an example of a text completion prompt and the generated output.
            Mention the specific model used for the completion (e.g., davinci-002).
            Discuss how LLMs can generate coherent and relevant text based on the given prompt.
        -->
        <div>
            <h2>Text Completion</h2>
            <ul>
                <li>Example prompt: "I have a dog and I want to name him but I don't know what to name him. I want a
                    name that is not too common and not too weird."</li>
                <li>Example completion: "List of dog name ideas: Rex, Spot, Buddy, Max, Charlie, Bailey, Molly,
                    Daisy, Lucy, Maggie, Rocky, Shadow, Toby, Bailey, Sadie, Molly, Maggie, Max, Charlie, Buddy,
                    Jack"</li>
                <li>Generated by davinci-002</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!--
            Explain the goal of creating AI systems that can respond to queries like a dedicated and helpful human.
            Mention that simply continuing a sentence in the most likely way is not enough to create a helpful assistant.
            Discuss how AI systems are trained to roleplay as helpful assistants to provide more useful and relevant responses. 
        -->
        <div>
            <h2>Helpful Assistant</h2>
            <ul>
                <li>We want AI to respond to queries like a dedicated and helpful human</li>
                <li>Continuing a sentence in the most likely way possible doesn't get you a helpful assistant</li>
                <li>The AI system is trained to roleplay as a helpful assistant</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>LLM prompting</h2>
            <ul>
                <li>Crafting specific prompts and breaking tasks into steps</li>
                <li>Iterative refinement and providing examples</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Discuss the trade-off between safety and usefulness in AI systems.
            Provide tips for effective LLM use, such as crafting specific prompts, breaking tasks into steps, iterative refinement, and providing examples.
            Emphasize the importance of responsible AI development and deployment.
        -->
        <div>
            <h2>AI Safety in Practice</h2>
            <ul>
                <li>Trade-off between safety and usefulness</li>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: DIFFUSION MODELS
    -->

    <div class="slide">
        <!-- 
            Introduce the concept of diffusion models for generating media.
            Provide a high-level overview of the diffusion process and how it works.
            Explain the potential applications of diffusion models in various domains.
        -->
        <div>
            <h2>Diffusion Models</h2>
            <ul>
                <li>Introduction to diffusion for generating media</li>
                <li>High-level overview of the diffusion process</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Present a showcase of impressive images and media generated using diffusion models.
            Discuss the current limitations of diffusion models and the lack of full control over the generated output.
            Highlight the potential for future improvements and advancements in diffusion models.
        -->
        <div>
            <h2>Diffusion Model Results</h2>
            <ul>
                <li>Showcase of impressive generated images and media</li>
                <li>Current limitations and lack of full control</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Introduce Comfy UI as an example of a platform or workflow being developed to use diffusion models locally and on the cloud.
            Provide a brief demo or overview of how Comfy UI works and its key features Discuss the potential benefits of using platforms like Comfy UI for diffusion model workflows.
        -->
        <div>
            <h2>Demo: Comfy UI</h2>
            <ul>
                <li>Platforms and workflows being developed to use this tech locally and on the cloud</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Share tips and strategies for effective prompt engineering when using diffusion models.
            Encourage experimentation with different tools and techniques, such as upscaling, to enhance the quality of generated media.
            Provide examples or case studies of successful prompt engineering and experimentation with diffusion models.
        -->
        <div>
            <h2>Tips for Using Diffusion Models</h2>
            <ul>
                <li>Prompt engineering strategies for diffusion</li>
                <li>Experimenting with different tools and upscaling</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Discuss recent progress and advancements in diffusion models, such as ControlNet.
            Highlight the potential for enhanced user control and customization in future diffusion models.
            Provide examples or demos of cutting-edge diffusion model techniques and their implications.
        -->
        <div>
            <h2>Advances in Diffusion Models</h2>
            <ul>
                <li>Recent progress and demos (e.g., ControlNet)</li>
                <li>Potential for enhanced user control and customization</li>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: CONCLUSION
    -->

    <div class="slide">
        <!--
            Summarize the key points covered in the presentation.
            Discuss the potential implications of LLMs and diffusion models for the development of Artificial General Intelligence (AGI).
            Encourage further exploration and responsible development of these technologies - Open the floor for questions and discussion. 
        -->
        <div>
            <h2>Conclusion and AGI</h2>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Call to Action</h2>
            <ul>
                <li>Continue learning about generative AI and its potential</li>
                <li>Use LLMs and diffusion models to enhance your work and creativity</li>
                <li>Contribute to the responsible development and deployment of AI</li>
                <li>Share your knowledge and engage in meaningful discussions</li>
                <li>Be a part of shaping the future of AI!</li>
            </ul>
        </div>
    </div>

    <div class="navigation"> <button class="prev-btn">&#8593;</button> <button class="next-btn">&#8595;</button>
    </div>
    <script src="script.js"></script>
</body>

</html>