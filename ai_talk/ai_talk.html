<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Talks Slideshow</title>
    <link rel="stylesheet" href="styles.css">
</head>

<!--
    INTRODUCTION SECTION:
    The introduction section serves to establish your credibility as a presenter and to provide context for the audience. 
    By sharing your background and motivation, you help the audience understand why they should listen to you and how the presentation will benefit them.
    The agenda slide gives a clear overview of what will be covered, setting expectations and providing a roadmap for the presentation.
    This section aligns with the goal of engaging the audience and preparing them to learn about generative AI.
-->

<!--
    AI BASICS SECTION:
    The AI basics section is crucial for building a foundation of understanding for non-experts. 
    By explaining key concepts such as artificial intelligence, machine learning, and supervised learning,
    you provide the audience with the necessary background knowledge to grasp the more advanced topics later in the presentation.
    The minimal example of classifying cats and dogs helps to make the concepts more concrete and relatable.
    This section aligns with the goal of providing a solid mental model by starting with the fundamentals and gradually building up to more complex ideas.
-->

<!--
    LARGE LANGUAGE MODELS SECTION:
    The large language models section dives into the specifics of LLMs, which are a key component of recent developments in generative AI.
    By explaining what LLMs are, how they work, and providing examples like ChatGPT, you help the audience understand the underlying technology behind popular AI tools.
    The discussion of the attention mechanism and the importance of training data helps to demystify the "magic" of AI and provides insights into how these models generate human-like text.
    The tips for effective LLM use and the emphasis on responsible AI development align with the goal of enabling the audience to improve their use of these tools and evaluate hype claims.
-->

<!--
    DIFFUSION MODELS SECTION:
    The diffusion models section introduces another important aspect of generative AI: media generation.
    By providing a high-level overview of the diffusion process and showcasing impressive generated images, you capture the audience's attention and demonstrate the potential of this technology.
    The discussion of current limitations and the demo of Comfy UI helps to ground the audience's expectations and provides practical insights into how these tools can be used.
    The tips for prompt engineering and the discussion of recent advances align with the goal of enabling the audience to effectively use these tools and stay informed about the latest developments.
-->

<!--
    CONCLUSION SECTION:
    The conclusion section serves to reinforce the key points covered in the presentation and to leave the audience with a lasting impression.
    By summarizing the main ideas and discussing the potential implications for AGI, you encourage the audience to continue exploring and thinking critically about these technologies.
    The call for responsible development and the opportunity for questions and discussion align with the goal of empowering the audience to engage with generative AI in a thoughtful and informed manner.
-->

<body>

    <!-- 
        SECTION START: INTRODUCTION
    -->

    <div class="slide">
        <div>
            <h2>Who Am I?</h2>
            <ul>
                <li>Software developer with a BSc in Computer Science.</li>
                <li>About a year experience in utilizing LLMs (ChatGPT) every day at work.</li>
                <ul>
                    <li>I don't develop AI systems, rather I utilize them to improve my programming.</li>
                </ul>
                <li>I have voraciously consuming the latest developments in generative AI.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Presentation structure</h2>
            <ul>
                <li>AI basics üß†</li>
                <ul>
                    <li>Key terms: AI, AGI</li>
                    <li>High-level walkthrough of image classification as a minimal example of a neural network</li>
                </ul>
                <li>Deep dive into Large Language Models üó£Ô∏è</li>
                <ul>
                    <li>Focus on next word prediction and attention mechanism</li>
                    <li>Concrete demonstrations to build an effective mental model</li>
                </ul>
                <li>Diffusion models for media generation üé®</li>
                <ul>
                    <li>A whirlwind tour of media generation and future prospects</li>
                </ul>
                <li>Conclusion and AI trajectory üöÄ</li>
                <ul>
                    <li>Scaling laws and model parameter count</li>
                    <li>Speculation about the capacity of models powered by next-generation computers</li>
                    <li>Tying back to the discussion of AGI and its implications</li>
                </ul>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Why learn about AI tools?</h2>
            <ul>
                <li><strong>Empowerment:</strong> Leveraging AI tools can empower you to create amazing work.</li>
                <ul>
                    <li>Like any skill utilizing AI tools improves with practice.</li>
                </ul>
                <li><strong>Rapid Improvement:</strong> AI is improving at a breathtaking pace, it seems likely that
                    almost all 'knowledge' and artist professions will be changed forever.</li>
                <ul>
                    <li>New jobs and artist developments will challenge existing institutions.</li>
                </ul>
                <li><strong>Informed Evaluation:</strong> Understanding how these tools work enables evaluation of 'AI
                    hype'.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <!--
        This slide shows a graph of gpt model sizes overtime to demonstrate the rapid growth in parameter count
    -->
        <div>
            <h2>Rapid Improvement?</h2>
            <img src="gpt_graph.png" alt="GPT Model Growth Graph" style="max-width:100%;height:auto;">
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Personal Anecdote: Birds with Hats üê¶üé©</h2>
            <ul>
                <li>When Dalle-3 came out, I had a lot of fun with the model's ability to generate characters,
                    specifically birds with hats, against a white background.</li>
                <li>Using this ability, I got GPT-4 to write code to remove the background and print a sticker sheet to
                    decorate my laptop.</li>
                <li>AI tools empowered me to complete a project I would have otherwise never attempted.</li>
            </ul>
            <div class="bird-container">
                <img src="birbs/eagle.png" alt="Eagle" class="bird-image">
                <img src="birbs/greyjay.png" alt="Grey Jay" class="bird-image">
                <img src="birbs/hawk.png" alt="Hawk" class="bird-image">
                <img src="birbs/magpie.png" alt="Magpie" class="bird-image">
                <img src="birbs/pelican.png" alt="Pelican" class="bird-image">

            </div>
        </div>
    </div>


    <!-- 
        SECTION START: AI BASICS
    -->
    <div class="slide">
        <div>
            <h2>Defining Artificial Intelligence (AI)</h2>
            <ul>
                <li>AI encompasses the development of computer systems capable of performing tasks that traditionally
                    require human intelligence.</li>
                <li> <strong>Task-Specific AI:</strong>
                    <ul>
                        <li>Designed for specialized tasks, demonstrating intelligence in a narrow domain.</li>
                        <li>Image recognition, speech recognition, and game-playing AI are examples of task-specific AI.
                        </li>
                    </ul>
                </li>
                <li> <strong>General AI (AGI):</strong>
                    <ul>
                        <li>Systems that excel across a wide range of tasks, potentially surpassing human capabilities.
                        </li>
                        <li>AGI could learn and adapt to new situations without explicit programming.</li>
                    </ul>
                </li>
                <li> <strong>Shifting Perception of AI</strong>
                    <ul>
                        <li>The definition of AI evolves as technology advances.</li>
                        <li>Tasks once considered uniquely human are now routinely performed by AI systems.</li>
                        <li>As AI capabilities expand, our understanding of what constitutes "true" intelligence also
                            shifts.</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Machine Learning: Bridging Data and AI</h2>
            <ul>
                <li>Machine learning enables computers to learn from data and improve their performance on tasks without
                    being explicitly programmed.</li>
                <li><strong>Adaptability:</strong> Just like humans learn from experience, machine learning models
                    refine their accuracy as they process more data.</li>
                <li><strong>Generalization:</strong> Machine learning models can identify patterns in data and apply
                    them to new, unseen situations, similar to how we use past experiences to navigate new challenges.
                </li>
                <li><strong>Efficiency:</strong> Automating the learning process allows machine learning to tackle
                    complex problems that would be impractical to solve with traditional programming methods.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Three Types of Machine Learning</h2>
            <ul>
                <li><strong>Supervised Learning:</strong></li>
                <ul>
                    <li>Learning from labeled examples, like a teacher guiding a student.</li>
                    <li>The algorithm learns to map input data to the correct output labels.</li>
                </ul>
                <li><strong>Unsupervised Learning:</strong></li>
                <ul>
                    <li>Discovering hidden patterns and structures in unlabeled data.</li>
                    <li>Similar to grouping similar objects together without prior knowledge of the categories.</li>
                </ul>
                <li><strong>Reinforcement Learning:</strong></li>
                <ul>
                    <li>Learning through interaction with an environment, like a child learning from trial and error.
                    </li>
                    <li>The algorithm receives rewards or penalties for its actions and learns to make better decisions
                        over time.</li>
                </ul>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Neural Networks: The Building Blocks of Modern AI</h2>
            <ul>
                <li>What are Neural Networks?
                    <ul>
                        <li>Neural networks are a type of machine learning algorithm inspired by the human brain.</li>
                        <li>Consist of interconnected nodes (neurons) organized in layers</li>
                    </ul>
                </li>
                <li>How do Neural Networks Learn?
                    <ul>
                        <li>Neurons receive inputs, process them, and pass outputs to the next layer</li>
                        <li>Connections between neurons have weights that determine the strength of the signal</li>
                        <li>Learning occurs by adjusting the weights to minimize prediction errors</li>
                    </ul>
                </li>
                <li>Advantages of Neural Networks
                    <ul>
                        <li>Able to learn complex patterns and relationships in data</li>
                        <li>Can handle large amounts of data and make accurate predictions</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>A Concrete Example: Recognizing Cats and Dogs</h2>
            <ul>
                <li>Problem: Teach a neural network to recognize images of cats and dogs</li>
                <li>Step 1: Collect and label a dataset of cat and dog images
                    <ul>
                        <li>Each image is labeled as either "cat" or "dog"</li>
                        <li>The dataset should be diverse and representative of various breeds, angles, and backgrounds
                        </li>
                    </ul>
                </li>
                <li>Step 2: Feed the labeled images into the neural network
                    <ul>
                        <li>The network processes the images and learns to extract relevant features</li>
                        <li>Features may include fur texture, ear shape, nose structure, etc.</li>
                    </ul>
                </li>
                <li>Step 3: The network learns by adjusting its weights to minimize prediction errors
                    <ul>
                        <li>It learns to associate certain features with cats and others with dogs</li>
                        <li>The goal is to minimize the difference between predicted and actual labels</li>
                    </ul>
                </li>
                <li>Step 4: Test the trained network on new, unseen cat and dog images
                    <ul>
                        <li>The network uses its learned features to classify the new images</li>
                        <li>The accuracy of the predictions is evaluated to assess the network's performance</li>
                    </ul>
                </li>
                <li>Result: The network can accurately classify new cat and dog images
                    <ul>
                        <li>It has learned to generalize from the training examples to make predictions on unseen data
                        </li>
                        <li>The network can be further improved by training on larger and more diverse datasets</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>From Image Classification to Generative AI</h2>
            <ul>
                <li>The principles of supervised learning, as demonstrated in the image classification example,
                    extend
                    to other domains and applications of AI.</li>
                <li>Generative AI is an exciting area that focuses on creating new content, such as images, text, or
                    music, based on learned patterns from training data.</li>
                <li>The success of generative AI relies on large-scale datasets, advanced model architectures, and
                    powerful computational resources.</li>
                <li>Generative AI has the potential to revolutionize various industries, from creative applications
                    like
                    art and design to practical use cases like data augmentation and simulation, by enabling
                    machines to
                    generate novel content that mimics human creativity.</li>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: LARGE LANGUAGE MODELS
    -->

    <div class="slide">
        <!-- 
            Explain what an LLM is and how it works.
            Discuss ChatGPT as a popular example of an LLM.
            Mention that LLMs are based on the attention mechanism and are essentially next-word prediction engines.
        -->
        <div>
            <h2>Large Language Models</h2>
            <ul>
                <li>What is an LLM?</li>
                <li>ChatGPT is a commercial product running on the GPT-3.5 or GPT-4 model</li>
                <li>Related to what people have seen (i.e., GPT-3.5)</li>
                <li>The most popular example is a large language model (LLM) based on the attention mechanism</li>
                <li>LLMs are next-word prediction engines</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Explain how an LLM generates text using a parameters file.
            Discuss the size of the parameters file and the hardware requirements for the best models.
            Mention that the parameters file is the result of training the neural network on a large corpus of text data.
            Highlight that the best models train on a substantial portion of the internet data at a huge expense.
        -->
        <div>
            <h2>What is inside an LLM?</h2>
            <ul>
                <li>An LLM generates text by referencing a parameters file to predict the next word in the sequence
                </li>
                <li>This file can be small and run on consumer hardware (think Macbook)</li>
                <li>The best models use huge parameters files (hundreds of GBs) and require specialized hardware
                </li>
                <li>A parameters file is the result of training the neural network</li>
                <li>This process compresses info from the training data into the output file</li>
                <li>The training data is often a corpus of text scraped off the internet (think sites like Reddit or
                    Wikipedia)</li>
                <li>The best models train on a substantial portion of the data available on the internet at huge
                    expense</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!--
            Explain the attention mechanism as the key innovation in LLMs.
            Compare the performance of traditional text prediction (e.g., phone keyboards) with LLMs like GPT-3.5.
            Provide examples to illustrate the difference in text completion quality between traditional methods and LLMs.
        -->
        <div>
            <h2>The Attention Mechanism</h2>
            <ul>
                <li>Attention as the key innovation in LLMs</li>
                <li>Text prediction has existed for a long time, but hasn't been particularly impressive</li>
                <li>Example: "I went to the Calgary Stampede and met a nice [day]" (phone keyboard)</li>
                <li>Example: "I went to the Calgary Stampede and met a nice [cowboy]." (GPT-3.5)</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!--
            Provide an example of a text completion prompt and the generated output.
            Mention the specific model used for the completion (e.g., davinci-002).
            Discuss how LLMs can generate coherent and relevant text based on the given prompt.
        -->
        <div>
            <h2>Text Completion</h2>
            <ul>
                <li>Example prompt: "I have a dog and I want to name him but I don't know what to name him. I want a
                    name that is not too common and not too weird."</li>
                <li>Example completion: "List of dog name ideas: Rex, Spot, Buddy, Max, Charlie, Bailey, Molly,
                    Daisy, Lucy, Maggie, Rocky, Shadow, Toby, Bailey, Sadie, Molly, Maggie, Max, Charlie, Buddy,
                    Jack"</li>
                <li>Generated by davinci-002</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!--
            Explain the goal of creating AI systems that can respond to queries like a dedicated and helpful human.
            Mention that simply continuing a sentence in the most likely way is not enough to create a helpful assistant.
            Discuss how AI systems are trained to roleplay as helpful assistants to provide more useful and relevant responses. 
        -->
        <div>
            <h2>Helpful Assistant</h2>
            <ul>
                <li>We want AI to respond to queries like a dedicated and helpful human</li>
                <li>Continuing a sentence in the most likely way possible doesn't get you a helpful assistant</li>
                <li>The AI system is trained to roleplay as a helpful assistant</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>LLM prompting</h2>
            <ul>
                <li>Crafting specific prompts and breaking tasks into steps</li>
                <li>Iterative refinement and providing examples</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Discuss the trade-off between safety and usefulness in AI systems.
            Provide tips for effective LLM use, such as crafting specific prompts, breaking tasks into steps, iterative refinement, and providing examples.
            Emphasize the importance of responsible AI development and deployment.
        -->
        <div>
            <h2>AI Safety in Practice</h2>
            <ul>
                <li>Trade-off between safety and usefulness</li>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: DIFFUSION MODELS
    -->

    <div class="slide">
        <!-- 
            Introduce the concept of diffusion models for generating media.
            Provide a high-level overview of the diffusion process and how it works.
            Explain the potential applications of diffusion models in various domains.
        -->
        <div>
            <h2>Diffusion Models</h2>
            <ul>
                <li>Introduction to diffusion for generating media</li>
                <li>High-level overview of the diffusion process</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Present a showcase of impressive images and media generated using diffusion models.
            Discuss the current limitations of diffusion models and the lack of full control over the generated output.
            Highlight the potential for future improvements and advancements in diffusion models.
        -->
        <div>
            <h2>Diffusion Model Results</h2>
            <ul>
                <li>Showcase of impressive generated images and media</li>
                <li>Current limitations and lack of full control</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Introduce Comfy UI as an example of a platform or workflow being developed to use diffusion models locally and on the cloud.
            Provide a brief demo or overview of how Comfy UI works and its key features Discuss the potential benefits of using platforms like Comfy UI for diffusion model workflows.
        -->
        <div>
            <h2>Demo: Comfy UI</h2>
            <ul>
                <li>Platforms and workflows being developed to use this tech locally and on the cloud</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Share tips and strategies for effective prompt engineering when using diffusion models.
            Encourage experimentation with different tools and techniques, such as upscaling, to enhance the quality of generated media.
            Provide examples or case studies of successful prompt engineering and experimentation with diffusion models.
        -->
        <div>
            <h2>Tips for Using Diffusion Models</h2>
            <ul>
                <li>Prompt engineering strategies for diffusion</li>
                <li>Experimenting with different tools and upscaling</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <!-- 
            Discuss recent progress and advancements in diffusion models, such as ControlNet.
            Highlight the potential for enhanced user control and customization in future diffusion models.
            Provide examples or demos of cutting-edge diffusion model techniques and their implications.
        -->
        <div>
            <h2>Advances in Diffusion Models</h2>
            <ul>
                <li>Recent progress and demos (e.g., ControlNet)</li>
                <li>Potential for enhanced user control and customization</li>
            </ul>
        </div>
    </div>

    <!-- 
        SECTION START: CONCLUSION
    -->

    <div class="slide">
        <!--
            Summarize the key points covered in the presentation.
            Discuss the potential implications of LLMs and diffusion models for the development of Artificial General Intelligence (AGI).
            Encourage further exploration and responsible development of these technologies - Open the floor for questions and discussion. 
        -->
        <div>
            <h2>Conclusion and AGI</h2>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Call to Action</h2>
            <ul>
                <li>Continue learning about generative AI and its potential</li>
                <li>Use LLMs and diffusion models to enhance your work and creativity</li>
                <li>Contribute to the responsible development and deployment of AI</li>
                <li>Share your knowledge and engage in meaningful discussions</li>
                <li>Be a part of shaping the future of AI!</li>
            </ul>
        </div>
    </div>

    <div class="navigation"> <button class="prev-btn">&#8593;</button> <button class="next-btn">&#8595;</button>
    </div>
    <script src="script.js"></script>
</body>

</html>