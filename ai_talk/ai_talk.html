<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Talks Slideshow</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div class="slide">
        <div>
            <h2>Who Am I?</h2>
            <ul>
                <li>Professional software engineer with a BSc in Computer Science</li>
                <li>Extensive experience using GPT-4 almost every day for about a year</li>
                <li>Passionate about the advancements in AI and eager to share knowledge and insights</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Motivation</h2>
            <ul>
                <li>Excitement and concern over recent developments in AI</li>
                <li>Desire to help others understand and effectively use AI tools</li>
                <li>Belief that knowledge of AI workings can enhance user outcomes</li>
                <li>Observation of AI's rapid improvement and its impact on daily life</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Agenda</h2>
            <ul>
                <li>Introduction to AI basics and their significance</li>
                <li>Deep dive into Large Language Models (LLM): Capabilities and practical uses</li>
                <li>Exploration of Diffusion Models: Media generation and user control</li>
                <li>Current limitations, ongoing rapid progress, and future prospects in AI technology</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>AI basics</h2>
            <ul>
                <li>What is AI?</li>
                <li>AI: Artificial Intelligence</li>
                <li>Computer systems that perform tasks requiring human-like intelligence</li>
                <li>Based on artificial neural networks inspired by the human brain</li>
                <li>AI systems "learn" and improve over time</li>
                <li>Machine Learning: Enabling computers to learn from data</li>
            </ul>
            <!-- AI, or Artificial Intelligence, refers to the development of computer systems that can perform tasks that typically require human intelligence. Today's AI is largely based on artificial neural networks, which are inspired by the structure and function of the human brain. AI systems are designed to "learn" and improve their performance on a specific task over time, without being explicitly programmed. The field of AI that focuses on enabling computers to learn from data is called Machine Learning. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Machine Learning: The Foundation of Modern AI</h2>
            <ul>
                <li>Machine Learning: A subfield of AI</li>
                <li>Enables computers to learn and improve without explicit programming</li>
                <li>Computers learn from large amounts of data</li>
                <li>Identify patterns, make predictions, and decisions</li>
                <li>Driving force behind recent AI advancements</li>
            </ul>
            <!-- Machine Learning is a subfield of AI that focuses on enabling computers to learn and improve their performance on a task without being explicitly programmed. In Machine Learning, the computer is fed large amounts of data and learns to identify patterns and make predictions or decisions based on that data. The more data the machine learning algorithm is exposed to, the better it becomes at its task. Machine Learning has been the driving force behind the recent advancements and applications of AI in various domains. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Three Types of Machine Learning</h2>
            <ul>
                <li>Three Types of Machine Learning</li>
                <li>Supervised Learning</li>
                <ul>
                    <li>Learning from labeled data</li>
                    <li>Mapping input data to correct output labels</li>
                </ul>
                <li>Unsupervised Learning</li>
                <ul>
                    <li>Finding patterns in unlabeled data</li>
                    <li>Discovering hidden patterns or groupings</li>
                </ul>
                <li>Reinforcement Learning</li>
                <ul>
                    <li>Learning through interaction with an environment</li>
                    <li>Receiving rewards or penalties for actions</li>
                </ul>
            </ul>
            <!-- There are three main types of Machine Learning: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves learning from labeled data, where the desired output is known. The algorithm learns to map input data to the correct output labels. Unsupervised learning involves finding patterns and structures in unlabeled data. The algorithm discovers hidden patterns or groupings in the data without any predefined labels. Reinforcement learning involves an agent learning to make decisions through interaction with an environment. The agent learns by receiving rewards or penalties for its actions. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Supervised Learning and Image Classification</h2>
            <ul>
                <li>Supervised Learning</li>
                <li>Most common type of Machine Learning</li>
                <li>Trained on labeled data (input + corresponding output label)</li>
                <li>Learns a mapping function to predict labels for new data</li>
                <li>Image Classification</li>
                <li>Application of supervised learning</li>
                <li>Assigning class labels to input images based on content</li>
            </ul>
            <!-- Supervised learning is the most common type of Machine Learning and is widely used in applications like image classification. In supervised learning, the algorithm is trained on a labeled dataset, where each example consists of an input (e.g., an image) and its corresponding output label (e.g., "cat" or "dog"). The goal is to learn a mapping function that can predict the correct label for new, unseen input data. Image classification is a popular application of supervised learning, where the task is to assign a class label to an input image based on its content. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>A Minimal Example: Classifying Cats and Dogs</h2>
            <ul>
                <li>Example: Classifying Cats and Dogs</li>
                <li>Labeled dataset:</li>
                <ul>
                    <li>Images of cats and dogs</li>
                    <li>Corresponding labels ("cat" or "dog")</li>
                </ul>
                <li>Dataset split:</li>
                <ul>
                    <li>Training set: Used to train the model</li>
                    <li>Test set: Used to evaluate the model's performance</li>
                </ul>
                <li>Model learns to extract features and map them to labels</li>
            </ul>
            <!-- Let's consider a minimal example of image classification: distinguishing between images of cats and dogs. To train a machine learning model for this task, we need a labeled dataset consisting of images of cats and dogs, along with their respective labels. The dataset is typically split into a training set, used to train the model, and a test set, used to evaluate the model's performance on unseen data. The model learns to extract relevant features from the images and map them to the corresponding labels during training. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>The Role of Labeled Data</h2>
            <ul>
                <li>Labeled Data: Crucial for Supervised Learning</li>
                <li>Each example: Input + Corresponding Output Label</li>
                <li>Quality and diversity of labeled data impact model performance</li>
                <li>Collecting and annotating labeled data can be time-consuming and expensive</li>
            </ul>
            <!-- Labeled data plays a crucial role in supervised learning, as it provides the ground truth for the model to learn from. Each example in the labeled dataset consists of an input (e.g., an image) and its corresponding output label (e.g., "cat" or "dog"). The quality and diversity of the labeled data directly impact the model's performance and its ability to generalize to new, unseen data. Collecting and annotating large amounts of labeled data can be time-consuming and expensive, but it is essential for training accurate models. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Training the Image Classifier</h2>
            <ul>
                <li>Training an Image Classifier</li>
                <li>Feed labeled dataset to a machine learning model (neural network)</li>
                <li>Model learns to map input images to corresponding labels</li>
                <li>Loss function measures the model's performance</li>
                <li>Model's parameters are updated to minimize the loss</li>
                <li>Training continues until satisfactory performance is reached</li>
            </ul>
            <!-- Training an image classifier involves feeding the labeled dataset to a machine learning model, typically a neural network. The model learns to map input images to their corresponding labels by adjusting its internal parameters. During training, the model's performance is measured using a loss function, which quantifies the difference between the predicted labels and the true labels. The model's parameters are iteratively updated to minimize the loss function, allowing the model to improve its predictions over time. The training process continues until the model reaches a satisfactory level of performance on the training data. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Evaluating the Trained Model</h2>
            <ul>
                <li>Evaluating the Trained Model</li>
                <li>Assess the model's performance on unseen data (test set)</li>
                <li>Evaluation metrics:</li>
                <ul>
                    <li>Accuracy: Overall correctness of predictions</li>
                    <li>Precision and Recall: Performance for each class</li>
                </ul>
                <li>Good performance on the test set indicates generalization ability</li>
                <li>Poor performance may suggest overfitting or biased data</li>
            </ul>
            <!-- After training, it is crucial to evaluate the model's performance on unseen data to assess its ability to generalize. The test set, which consists of labeled examples that were not used during training, is used for evaluation. Common evaluation metrics for image classification include accuracy, precision, recall, and F1 score. Accuracy measures the overall correctness of the model's predictions, while precision and recall focus on the model's performance for each class. If the model performs well on the test set, it indicates that it has learned meaningful patterns and can generalize to new data. However, if the model performs poorly on the test set, it may suggest issues like overfitting or biased data. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>From Image Classification to Generative AI</h2>
            <ul>
                <li>From Image Classification to Generative AI</li>
                <li>Principles of supervised learning extend to other domains</li>
                <li>Generative AI: Creating new content based on learned patterns</li>
                <li>Generative models (GANs, VAEs) capture data distribution and generate new samples</li>
                <li>Success relies on large-scale datasets, advanced architectures, and computational resources</li>
                <li>Potential to revolutionize industries (art, design, data augmentation, simulation)</li>
            </ul>
            <!-- The principles of supervised learning, as demonstrated in the image classification example, extend to other domains and applications of AI. Generative AI is an exciting area that focuses on creating new content, such as images, text, or music, based on learned patterns from training data. Generative models, like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), learn to capture the underlying distribution of the training data and generate new samples that resemble the original data. The success of generative AI relies on large-scale datasets, advanced model architectures, and powerful computational resources. Generative AI has the potential to revolutionize various industries, from creative applications like art and design to practical use cases like data augmentation and simulation. -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Large Language Models</h2>
            <ul>
                <li>What is an LLM?</li>
                <li>ChatGPT is a commercial product running on the GPT-3.5 or GPT-4 model</li>
                <li>Related to what people have seen (i.e., GPT-3.5)</li>
                <li>The most popular example is a large language model (LLM) based on the attention mechanism</li>
                <li>LLMs are next-word prediction engines</li>
            </ul>
            <!-- Speaker notes: - Explain what an LLM is and how it works - Discuss ChatGPT as a popular example of an LLM - Mention that LLMs are based on the attention mechanism and are essentially next-word prediction engines -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>What is inside an LLM?</h2>
            <ul>
                <li>An LLM generates text by referencing a parameters file to predict the next word in the sequence
                </li>
                <li>This file can be small and run on consumer hardware (think Macbook)</li>
                <li>The best models use huge parameters files (hundreds of GBs) and require specialized hardware
                </li>
                <li>A parameters file is the result of training the neural network</li>
                <li>This process compresses info from the training data into the output file</li>
                <li>The training data is often a corpus of text scraped off the internet (think sites like Reddit or
                    Wikipedia)</li>
                <li>The best models train on a substantial portion of the data available on the internet at huge
                    expense</li>
            </ul>
            <!-- Speaker notes: - Explain how an LLM generates text using a parameters file - Discuss the size of the parameters file and the hardware requirements for the best models - Mention that the parameters file is the result of training the neural network on a large corpus of text data - Highlight that the best models train on a substantial portion of the internet data at a huge expense -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>The Attention Mechanism</h2>
            <ul>
                <li>Attention as the key innovation in LLMs</li>
                <li>Text prediction has existed for a long time, but hasn't been particularly impressive</li>
                <li>Example: "I went to the Calgary Stampede and met a nice [day]" (phone keyboard)</li>
                <li>Example: "I went to the Calgary Stampede and met a nice [cowboy]." (GPT-3.5)</li>
            </ul>
            <!-- Speaker notes: - Explain the attention mechanism as the key innovation in LLMs - Compare the performance of traditional text prediction (e.g., phone keyboards) with LLMs like GPT-3.5 - Provide examples to illustrate the difference in text completion quality between traditional methods and LLMs -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Text Completion</h2>
            <ul>
                <li>Example prompt: "I have a dog and I want to name him but I don't know what to name him. I want a
                    name that is not too common and not too weird."</li>
                <li>Example completion: "List of dog name ideas: Rex, Spot, Buddy, Max, Charlie, Bailey, Molly,
                    Daisy, Lucy, Maggie, Rocky, Shadow, Toby, Bailey, Sadie, Molly, Maggie, Max, Charlie, Buddy,
                    Jack"</li>
                <li>Generated by davinci-002</li>
            </ul>
            <!-- Speaker notes: - Provide an example of a text completion prompt and the generated output - Mention the specific model used for the completion (e.g., davinci-002) - Discuss how LLMs can generate coherent and relevant text based on the given prompt -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Helpful Assistant</h2>
            <ul>
                <li>We want AI to respond to queries like a dedicated and helpful human</li>
                <li>Continuing a sentence in the most likely way possible doesn't get you a helpful assistant</li>
                <li>The AI system is trained to roleplay as a helpful assistant</li>
            </ul>
            <!-- Speaker notes: - Explain the goal of creating AI systems that can respond to queries like a dedicated and helpful human - Mention that simply continuing a sentence in the most likely way is not enough to create a helpful assistant - Discuss how AI systems are trained to roleplay as helpful assistants to provide more useful and relevant responses -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>AI Safety in Practice</h2>
            <ul>
                <li>Trade-off between safety and usefulness</li>
                <li>Tips for Effective LLM Use: <ul>
                        <li>Crafting specific prompts and breaking tasks into steps</li>
                        <li>Iterative refinement and providing examples</li>
                    </ul>
                </li>
            </ul>
            <!-- Speaker notes: - Discuss the trade-off between safety and usefulness in AI systems - Provide tips for effective LLM use, such as crafting specific prompts, breaking tasks into steps, iterative refinement, and providing examples - Emphasize the importance of responsible AI development and deployment -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Diffusion Models</h2>
            <ul>
                <li>Introduction to diffusion for generating media</li>
                <li>High-level overview of the diffusion process</li>
            </ul>
            <!-- Speaker notes: - Introduce the concept of diffusion models for generating media - Provide a high-level overview of the diffusion process and how it works - Explain the potential applications of diffusion models in various domains -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Diffusion Model Results</h2>
            <ul>
                <li>Showcase of impressive generated images and media</li>
                <li>Current limitations and lack of full control</li>
            </ul>
            <!-- Speaker notes: - Present a showcase of impressive images and media generated using diffusion models - Discuss the current limitations of diffusion models and the lack of full control over the generated output - Highlight the potential for future improvements and advancements in diffusion models -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Demo: Comfy UI</h2>
            <ul>
                <li>Platforms and workflows being developed to use this tech locally and on the cloud</li>
            </ul>
            <!-- Speaker notes: - Introduce Comfy UI as an example of a platform or workflow being developed to use diffusion models locally and on the cloud - Provide a brief demo or overview of how Comfy UI works and its key features - Discuss the potential benefits of using platforms like Comfy UI for diffusion model workflows -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Tips for Using Diffusion Models</h2>
            <ul>
                <li>Prompt engineering strategies for diffusion</li>
                <li>Experimenting with different tools and upscaling</li>
            </ul>
            <!-- Speaker notes: - Share tips and strategies for effective prompt engineering when using diffusion models - Encourage experimentation with different tools and techniques, such as upscaling, to enhance the quality of generated media - Provide examples or case studies of successful prompt engineering and experimentation with diffusion models -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Advances in Diffusion Models</h2>
            <ul>
                <li>Recent progress and demos (e.g., ControlNet)</li>
                <li>Potential for enhanced user control and customization</li>
            </ul>
            <!-- Speaker notes: - Discuss recent progress and advancements in diffusion models, such as ControlNet - Highlight the potential for enhanced user control and customization in future diffusion models - Provide examples or demos of cutting-edge diffusion model techniques and their implications -->
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Conclusion and AGI</h2>
            <!-- Speaker notes: - Summarize the key points covered in the presentation - Discuss the potential implications of LLMs and diffusion models for the development of Artificial General Intelligence (AGI) - Encourage further exploration and responsible development of these technologies - Open the floor for questions and discussion -->
        </div>
    </div>

    <div class="navigation"> <button class="prev-btn">&#8593;</button> <button class="next-btn">&#8595;</button> </div>
    <script src="script.js"></script>
</body>

</html>