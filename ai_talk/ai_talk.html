<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Talks Slideshow</title>
    <link rel="stylesheet" href="slide_style.css">
    <link rel="stylesheet" href="ai_talk.css">
</head>
<!-- imitataion game 
side by side comparison of model sizes 
importance of use in training and studying -->

<body>
    <div class="slide">
        <div>
            <img src="sections/mountain_timelapse_1.webp" alt="timelapse" style="max-width:100%;height:auto;">
            <h1 class="floating-title">Using AI tools</h1>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Who Am I?</h2>
            <ul>
                <li>Software developer with a BSc in Computer Science.</li>
                <li>About a year experience in utilizing LLMs (ChatGPT) every day at work.</li>
                <ul>
                    <li>I don't develop AI systems, rather I utilize them to improve my programming.</li>
                </ul>
                <li>I have voraciously consuming the latest developments in generative AI.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Presentation structure</h2>
            <ul>
                <li>AI basics üß†</li>
                <ul>
                    <li>Key terms: AI, AGI</li>
                    <li>High-level walkthrough of image classification as a minimal example of a neural network</li>
                </ul>
                <li>Deep dive into Large Language Models üó£Ô∏è</li>
                <ul>
                    <li>Focus on next word prediction and attention mechanism</li>
                    <li>Concrete demonstrations to build an effective mental model</li>
                </ul>
                <li>Diffusion models for media generation üé®</li>
                <ul>
                    <li>A whirlwind tour of media generation and future prospects</li>
                </ul>
                <li>Conclusion and AI trajectory üöÄ</li>
                <ul>
                    <li>Scaling laws and model parameter count</li>
                    <li>Speculation about the capacity of models powered by next-generation computers</li>
                    <li>Tying back to the discussion of AGI and its implications</li>
                </ul>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Why learn about AI tools?</h2>
            <ul>
                <li><strong>Empowerment:</strong> Leveraging AI tools can empower you to create amazing work.</li>
                <ul>
                    <li>Like any skill utilizing AI tools improves with practice.</li>
                </ul>
                <li><strong>Rapid Improvement:</strong> AI is improving at a breathtaking pace, it seems likely that
                    almost all 'knowledge' and artist professions will be changed forever.</li>
                <ul>
                    <li>New jobs and artist developments will challenge existing institutions.</li>
                </ul>
                <li><strong>Informed Evaluation:</strong> Understanding how these tools work enables evaluation of 'AI
                    hype'.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <!--
        This slide shows a graph of gpt model sizes overtime to demonstrate the rapid growth in parameter count
    -->
        <div>
            <h2>Rapid Improvement?</h2>
            <img src="gpt_graph.png" alt="GPT Model Growth Graph" style="max-width:100%;height:auto;">
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Personal Anecdote: Birds with Hats üê¶üé©</h2>
            <ul>
                <li>When Dalle-3 came out, I had a lot of fun with the model's ability to generate characters,
                    specifically birds with hats, against a white background.</li>
                <li>Using this ability, I got GPT-4 to write code to remove the background and print a sticker sheet to
                    decorate my laptop.</li>
                <li>AI tools empowered me to complete a project I would have otherwise never attempted.</li>
            </ul>
            <div class="image-row">
                <img src="birbs/eagle.png" alt="Eagle" class="bird-image">
                <img src="birbs/greyjay.png" alt="Grey Jay" class="bird-image">
                <img src="birbs/hawk.png" alt="Hawk" class="bird-image">
                <img src="birbs/magpie.png" alt="Magpie" class="bird-image">
                <img src="birbs/pelican.png" alt="Pelican" class="bird-image">
                <img src="birbs/chickadee.png" alt="Pelican" class="bird-image">
                <img src="birbs/ptarmigan.png" alt="Pelican" class="bird-image">

            </div>
        </div>
    </div>


    <div class="slide">
        <div>
            <img src="sections/downtown.webp" alt="timelapse" style="max-width:100%;height:auto;">
            <h1 class="floating-title">Using AI tools</h1>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Defining Artificial Intelligence (AI)</h2>
            <ul>
                <li>AI encompasses the development of computer systems capable of performing tasks that traditionally
                    require human intelligence.</li>
                <li> <strong>Task-Specific AI:</strong>
                    <ul>
                        <li>Designed for specialized tasks, demonstrating intelligence in a narrow domain.</li>
                        <li>Image recognition, speech recognition, and game-playing AI are examples of task-specific AI.
                        </li>
                    </ul>
                </li>
                <li> <strong>General AI (AGI):</strong>
                    <ul>
                        <li>Systems that excel across a wide range of tasks, potentially surpassing human capabilities.
                        </li>
                        <li>AGI could learn and adapt to new situations without explicit programming.</li>
                    </ul>
                </li>
                <li> <strong>Shifting Perception of AI</strong>
                    <ul>
                        <li>The definition of AI evolves as technology advances.</li>
                        <li>Tasks once considered uniquely human are now routinely performed by AI systems.</li>
                        <li>As AI capabilities expand, our understanding of what constitutes "true" intelligence also
                            shifts.</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Machine Learning: Bridging Data and AI</h2>
            <ul>
                <li><strong>Adaptability:</strong> Just like humans learn from experience, machine learning models
                    refine their accuracy as they process more data.</li>
                <li><strong>Generalization:</strong> Machine learning models can identify patterns in data and apply
                    them to new, unseen situations, similar to how we use past experiences to navigate new challenges.
                </li>
                <li><strong>Efficiency:</strong> Automating the learning process allows machine learning to tackle
                    complex problems that would be impractical to solve with traditional programming methods.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Three Types of Machine Learning</h2>
            <ul>
                <li><strong>Supervised Learning:</strong></li>
                <ul>
                    <li>Learning from labeled examples, like a teacher guiding a student.</li>
                    <li>The algorithm learns to map input data to the correct output labels.</li>
                </ul>
                <li><strong>Unsupervised Learning:</strong></li>
                <ul>
                    <li>Discovering hidden patterns and structures in unlabeled data.</li>
                    <li>Similar to grouping similar objects together without prior knowledge of the categories.</li>
                </ul>
                <li><strong>Reinforcement Learning:</strong></li>
                <ul>
                    <li>Learning through interaction with an environment, like a child learning from trial and error.
                    </li>
                    <li>The algorithm receives rewards or penalties for its actions and learns to make better decisions
                        over time.</li>
                </ul>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Neural Networks: The Building Blocks of Modern AI</h2>
            <ul>
                <li>What are Neural Networks?
                    <ul>
                        <li>Neural networks are a type of machine learning algorithm inspired by the human brain.</li>
                        <li>Consist of interconnected nodes (neurons) organized in layers</li>
                    </ul>
                </li>
                <li>How do Neural Networks Learn?
                    <ul>
                        <li>Neurons receive inputs, process them, and pass outputs to the next layer</li>
                        <li>Connections between neurons have weights that determine the strength of the signal</li>
                        <li>Learning occurs by adjusting the weights to minimize prediction errors</li>
                    </ul>
                </li>
                <li>Advantages of Neural Networks
                    <ul>
                        <li>Able to learn complex patterns and relationships in data</li>
                        <li>Can handle large amounts of data and make accurate predictions</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>A Concrete Example: Recognizing Cats and Dogs</h2>
            <ul>
                <li>Let's explore a practical application of neural networks: teaching a model to recognize images of
                    cats and dogs.</li>
                <li>This example will demonstrate the key steps involved in training a neural network for image
                    classification.</li>
                <li>By understanding this process, you'll gain insights into how AI systems learn from data and make
                    predictions.</li>
            </ul>
            <div class="image-row">
                <img src="cats_dogs/cat1.png" alt="Cat 1" class="image-row-item">
                <img src="cats_dogs/dog1.png" alt="Dog 1" class="image-row-item">
                <img src="cats_dogs/cat2.png" alt="Cat 2" class="image-row-item">
                <img src="cats_dogs/dog2.png" alt="Dog 2" class="image-row-item">
                <img src="cats_dogs/cat3.png" alt="Cat 3" class="image-row-item">
                <img src="cats_dogs/dog3.png" alt="Dog 3" class="image-row-item">
                <img src="cats_dogs/cat4.png" alt="Cat 4" class="image-row-item">
                <img src="cats_dogs/dog4.png" alt="Dog 4" class="image-row-item">
                <img src="cats_dogs/cat5.png" alt="Cat 2" class="image-row-item">
                <img src="cats_dogs/dog5.png" alt="Dog 2" class="image-row-item">
            </div>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Step 1: Collect and Label a Dataset</h2>
            <ul>
                <li>The first step is to gather a dataset of cat and dog images and label each image accordingly.</li>
                <li>Labeling involves assigning the correct category ("cat" or "dog") to each image in the dataset.</li>
                <li>Key Point: The quality and diversity of the dataset are crucial for the model's performance. The
                    dataset should include various breeds, angles, and backgrounds to ensure the model learns robust
                    features.</li>
            </ul>
            <div class="image-row">
                <div class="image-label-container"> <img src="cats_dogs/cat1.png" alt="Cat 1" class="image-row-item">
                    <div class="image-label">Cat</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/dog1.png" alt="Dog 1" class="image-row-item">
                    <div class="image-label">Dog</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/cat2.png" alt="Cat 2" class="image-row-item">
                    <div class="image-label">Cat</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/dog2.png" alt="Dog 2" class="image-row-item">
                    <div class="image-label">Dog</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/cat3.png" alt="Cat 3" class="image-row-item">
                    <div class="image-label">Cat</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/dog3.png" alt="Dog 3" class="image-row-item">
                    <div class="image-label">Dog</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/cat4.png" alt="Cat 4" class="image-row-item">
                    <div class="image-label">Cat</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/dog4.png" alt="Dog 4" class="image-row-item">
                    <div class="image-label">Dog</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/cat5.png" alt="Cat 5" class="image-row-item">
                    <div class="image-label">Cat</div>
                </div>
                <div class="image-label-container"> <img src="cats_dogs/dog5.png" alt="Dog 5" class="image-row-item">
                    <div class="image-label">Dog</div>
                </div>
            </div>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Step 2: Feed the Labeled Images into the Neural Network</h2>
            <ul>
                <li>The labeled images are then fed into the neural network for training.</li>
                <li>The network processes the images and learns to extract relevant features that distinguish cats from
                    dogs.</li>
                <li>Key Point: The neural network automatically learns hierarchical features from the raw pixel data.
                    Lower layers capture simple features like edges and textures, while higher layers learn more complex
                    and abstract features specific to cats and dogs.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Step 3: Adjusting Weights to Minimize Prediction Errors</h2>
            <ul>
                <li>During training, the network adjusts its internal weights to minimize the difference between
                    predicted and actual labels.</li>
                <li>It learns to associate certain features with cats and others with dogs based on the labeled
                    examples.</li>
                <li>Key Point: The learning process involves iteratively updating the weights through a technique called
                    backpropagation. By minimizing the prediction errors, the network gradually improves its ability to
                    classify cats and dogs accurately.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Step 4: Testing the Trained Network</h2>
            <ul>
                <li>After training, the network is tested on new, unseen cat and dog images to evaluate its performance.
                </li>
                <li>The network uses its learned features to classify the new images as either cats or dogs.</li>
                <li>Key Point: Testing on unseen data helps assess the network's ability to generalize beyond the
                    training examples. A well-trained model should be able to accurately classify new images it hasn't
                    encountered before.</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Conclusion: Recognizing Cats and Dogs</h2>
            <ul>
                <li>Through this example, we've seen how a neural network can be trained to recognize cats and dogs in
                    images.</li>
                <li>The network learns from labeled examples, extracts relevant features, and adjusts its weights to
                    make accurate predictions.</li>
                <li>Key Takeaways: <ul>
                        <li>AI systems learn from data by identifying patterns and relationships.</li>
                        <li>The quality and diversity of the training data significantly impact the model's performance.
                        </li>
                        <li>Neural networks can automatically learn hierarchical features from raw data.</li>
                        <li>Generalization is a crucial aspect of AI, enabling models to make predictions on unseen
                            data.</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>From Image Classification to Generative AI</h2>
            <ul>
                <li>The principles of supervised learning, as demonstrated in the image classification example,
                    extend
                    to other domains and applications of AI.</li>
                <li>Generative AI is an exciting area that focuses on creating new content, such as images, text, or
                    music, based on learned patterns from training data.</li>
                <li>The success of generative AI relies on large-scale datasets, advanced model architectures, and
                    powerful computational resources.</li>
                <li>Generative AI has the potential to revolutionize various industries, from creative applications
                    like
                    art and design to practical use cases like data augmentation and simulation, by enabling
                    machines to
                    generate novel content that mimics human creativity.</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <img src="sections/mountain_timelapse_2.webp" alt="timelapse" style="max-width:100%;height:auto;">
            <h1 class="floating-title">Large Language Model background</h1>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Introduction to Large Language Models (LLMs)</h2>
            <ul>
                <li>LLMs are powerful AI models designed for natural language processing tasks</li>
                <li>They are built upon the concepts of neural networks and machine learning discussed earlier</li>
                <li>LLMs have revolutionized the field of natural language processing and opened up new possibilities
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>The Building Blocks of LLMs</h2>
            <ul>
                <li>LLMs are based on the transformer architecture, which enables specific computer hardware to
                    massively speed computation.</li>
                <li>Callback: The transformer architecture is a more advanced example of the neural networks discussed
                    previously.
                    architecture discussion</li>
                <li>Self-attention is a key component that allows LLMs to capture long-range dependencies in text</li>
                <li>The scalability of LLMs allows them to handle vast amounts of text data and learn from diverse
                    sources</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>How LLMs Generate Text</h2>
            <ul>
                <li>LLMs generate text by predicting the next word in a sequence based on the previous words</li>
                <li>The process involves iteratively selecting the most probable next word until a stopping criterion is
                    met</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Compressing the Internet</h2>
            <ul>
                <li>The parameters file of LLMs is like a compressed version of the vast information available on the
                    internet</li>
                <li>Just as machine learning models learn from labeled datasets, LLMs learn from diverse online sources
                    to
                    capture a wide range of knowledge</li>
                <li>A well-trained LLM becomes a model of the world, encapsulating not only language patterns but also
                    real-world knowledge and relationships</li>
                <li>This process is analogous to how the cat and dog image classification model learns from a labeled
                    dataset to recognize patterns and make predictions</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>The Power of Attention Mechanism</h2>
            <ul>
                <li>Attention, a crucial component of neural networks, enables LLMs to focus on relevant parts of the
                    input
                </li>
                <li>In the context of LLMs, attention allows the model to consider the context and generate more
                    coherent
                    and contextually relevant text</li>
                <li>Example (no attention): "I went to the Calgary Stampede and met a nice [day]" (phone keyboard)</li>
                <li>Example (w/ attention): "I went to the Calgary Stampede and met a nice [cowboy]." (GPT-3.5)</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Text Completion and Contextual Understanding</h2>
            <ul>
                <li>LLMs excel at text completion tasks, generating contextually relevant continuations of given prompts
                </li>
                <li>Example prompt: "I have a dog and I want to name him but I don't know what to name him. I want a
                    name that is not too common and not too weird."</li>
                <li>Example completion: "List of dog name ideas: Rex, Spot, Buddy, Max, Charlie, Bailey, Molly, Daisy,
                    Lucy, Maggie, Rocky, Shadow, Toby, Bailey, Sadie, Molly, Maggie, Max, Charlie, Buddy, Jack"</li>
                <li>LLMs demonstrate a deep understanding of context and can generate coherent and relevant completions
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Beyond Completion: The Helpful Assistant</h2>
            <ul>
                <li>LLMs can be trained to take on the persona of a helpful assistant, providing valuable support and
                    guidance</li>
                <li>Reinforcement learning techniques, similar to those discussed in the AI basics section, are used to
                    fine-tune LLM responses and optimize for helpfulness</li>
                <li>Personal anecdote: I recently used an AI-powered writing assistant to help me draft a professional
                    email. The assistant provided suggestions on tone, grammar, and structure, saving me time and
                    ensuring a
                    polished final product.</li>
                <li>LLMs as helpful assistants have potential applications in customer support, tutoring, and more</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Balancing AI Safety and Usefulness</h2>
            <ul>
                <li>There is a trade-off between safety and usefulness in LLMs</li>
                <li>Efforts to make LLMs safe and avoid harmful outputs can sometimes result in unnecessary refusals
                </li>
                <li>Finding the right balance is crucial to maximize the benefits of LLMs while mitigating potential
                    risks</li>
            </ul>
        </div>
    </div>


    <div class="slide">
        <div>
            <img src="mary_lamb.png" alt="her fleece as white as copyright infringement"
                style="max-width:100%;height:auto;">
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>The Future of LLMs</h2>
            <ul>
                <li>As new high performance AI accelerator hardware is released, we can expect LLMs to become more
                    capable of
                    handling complex language tasks.</li>
                <li>'Big tech' is scrambling to include LLMs into consumer products (ie. Microsoft Office)</li>
                <li>With better LLMs creating 'autonomous agents' will become more viable, enabling LLMs to prompt
                    themselves to solve complex problems</li>
                <li>The advancements in LLM technology could have significant impacts across various industries and
                    domains
                </li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <img src="sections/mountain_timelapse_3.webp" alt="timelapse" style="max-width:100%;height:auto;">
            <h1 class="floating-title">LLM prompting</h1>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Introduction to LLM Prompting</h2>
            <ul>
                <li>LLM prompting is the art of crafting input prompts to elicit desired responses from LLMs</li>
                <li>Effective prompting is crucial for unlocking the full potential of LLMs and achieving desired
                    outcomes</li>
                <li>Prompting techniques can significantly influence the quality and relevance of LLM-generated text
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Crafting Specific Prompts</h2>
            <ul>
                <li>Crafting specific and well-defined prompts is essential for guiding LLM behavior</li>
                <li>Example of a specific prompt: "Write a short story about a magical adventure in a enchanted forest"
                </li>
                <li>Tips for creating effective prompts: <ul>
                        <li>Be clear and concise</li>
                        <li>Provide relevant context and constraints</li>
                        <li>Use appropriate language and terminology</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Breaking Tasks into Steps</h2>
            <ul>
                <li>Breaking complex tasks into smaller, manageable steps can improve LLM performance and accuracy</li>
                <li>Example of a multi-step prompt: <ol>
                        <li>Generate a list of five potential book titles for a science fiction novel</li>
                        <li>Select the most intriguing title from the list</li>
                        <li>Write a brief synopsis of the novel based on the selected title</li>
                    </ol>
                </li>
                <li>Breaking tasks into steps allows LLMs to focus on specific subtasks and generate more coherent
                    outputs</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Iterative Refinement</h2>
            <ul>
                <li>Iterative refinement involves iterating on prompts based on LLM responses to improve results</li>
                <li>The process typically involves: <ol>
                        <li>Providing an initial prompt</li>
                        <li>Analyzing the LLM-generated response</li>
                        <li>Refining the prompt based on the observed strengths and weaknesses</li>
                        <li>Repeating the process until the desired output is achieved</li>
                    </ol>
                </li>
                <li>Iterative refinement allows for fine-tuning prompts and optimizing LLM performance on specific tasks
                </li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Using Examples to Guide LLM Behavior</h2>
            <ul>
                <li>Providing relevant examples in prompts can help LLMs understand the desired output format or style
                </li>
                <li>Example-based prompting: <ul>
                        <li>Prompt: "Generate a product review in the style of the following example: [example review]"
                        </li>
                        <li>LLM generates a review that mimics the style and structure of the provided example</li>
                    </ul>
                </li>
                <li>Examples serve as a template or reference for LLMs to follow, improving the consistency and quality
                    of generated text</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Advanced Prompting Techniques</h2>
            <ul>
                <li>Few-shot learning: Providing a small number of examples in the prompt to guide LLM behavior</li>
                <li>Prompt chaining: Combining multiple prompts sequentially to perform complex tasks</li>
                <li>Example of few-shot learning: <ul>
                        <li>Prompt: "Translate the following sentences from English to French:</li>
                        <li>1. Hello, how are you? ‚Üí Bonjour, comment allez-vous?</li>
                        <li>2. Thank you very much. ‚Üí Merci beaucoup.</li>
                        <li>3. I love learning new languages.</li>
                    </ul>
                </li>
                <li>Advanced prompting techniques can enhance LLM performance on specific tasks and domains</li>
            </ul>
        </div>
    </div>
    <div class="slide">
        <div>
            <h2>Prompting Best Practices and Guidelines</h2>
            <ul>
                <li>Key takeaways and best practices for effective LLM prompting: <ul>
                        <li>Be clear, specific, and concise in your prompts</li>
                        <li>Provide relevant context and constraints</li>
                        <li>Break complex tasks into smaller, manageable steps</li>
                        <li>Use examples to guide LLM behavior</li>
                        <li>Iterate and refine prompts based on LLM responses</li>
                    </ul>
                </li>
                <li>Experiment with different prompting techniques and share your experiences with the community</li>
                <li>Continuously learn and adapt your prompting strategies as LLMs evolve and improve</li>
            </ul>
        </div>
    </div>

    <div class="slide">
        <div>
            <img src="sections/mountain_timelapse_4.webp" alt="timelapse" style="max-width:100%;height:auto;">
            <h1 class="floating-title">Conclusion</h1>
        </div>
    </div>

    <div class="slide">
        <div>
            <h2>Call to Action</h2>
            <ul>
                <li>Continue learning about generative AI and its potential</li>
                <li>Use LLMs and diffusion models to enhance your work and creativity</li>
                <li>Contribute to the responsible development and deployment of AI</li>
                <li>Share your knowledge and engage in meaningful discussions</li>
                <li>Be a part of shaping the future of AI!</li>
            </ul>
        </div>
    </div>

    <div class="navigation"> <button class="prev-btn">&#8593;</button> <button class="next-btn">&#8595;</button>
    </div>
    <script src="script.js"></script>
</body>

</html>